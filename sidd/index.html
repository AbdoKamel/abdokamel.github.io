<!DOCTYPE html>
<html lang="en">

<head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>SIDD</title>
        <link rel="shortcut icon" href="./favicon.ico" type="image/ico" />
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-119390362-1"></script>
        <script>
                window.dataLayer = window.dataLayer || [];
                function gtag() { dataLayer.push(arguments); }
                gtag('js', new Date());

                gtag('config', 'UA-119390362-1');
        </script>
        <!--<link rel="stylesheet" href="css/reset.css"> -->
        <link rel="stylesheet" href="css/styles.css">
        <script type="text/javascript" src="js/scripts.js"></script>
        <!-- for slider -->
        <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,300,700' rel='stylesheet' type='text/css'>
        <script src="js/modernizr.js"></script>
        <!-- table sorting -->
        <script src="js/sort_table.js"></script>
        <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
        <script src="js/jquery-2.1.1.js"></script>
        <script src="js/jquery.mobile.custom.min.js"></script> <!-- Resource jQuery -->
        <script src="js/main.js"></script> <!-- Resource jQuery -->
        <script type="text/javascript" id="clustrmaps"
                src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=100&t=tt&d=6uI6fWhTRLqfKkvEqmoA8WE3G0NVLiwBNW5Zl-6i4Ig"></script>
</head>

<body onload="sortTable(event, 't01', 1); sortTable(event, 't02', 1); changePage();">
        <div class="head-container">
                <div class="head-container">
                        <div style="width: 100%; text-align:center;">
                                <h1>Smartphone Image Denoising Dataset</h1>
                                <p>
                                        <a href="https://abdokamel.github.io/" target="_blank"
                                                rel="noopener">Abdelrahman
                                                Abdelhamed</a><sup>1</sup>
                                        &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
                                        <a href="https://www.microsoft.com/en-us/research/people/stevelin/"
                                                target="_blank" rel="noopener">Stephen Lin</a><sup>2</sup>
                                        &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
                                        <a href="https://www.eecs.yorku.ca/~mbrown/" target="_blank">Michael S.
                                                Brown</a><sup>1</sup>
                                </p>

                                <p>
                                        <sup>1</sup><a href="http://eecs.lassonde.yorku.ca/" target="_blank"
                                                rel="noopener">York
                                                University</a>
                                        &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
                                        <sup>2</sup><a href="https://www.microsoft.com/en-us/research/" target="_blank"
                                                rel="noopener">Microsoft Research</a>

                                </p>
                        </div>
                </div>
                <p>
					<a href="http://130.63.97.225/sidd/benchmark_submit.php" class="button-block">Click here to
                                submit your
                                results</a>
					<p style="color: red;">
						The evaluation server is currently down (Sorry about that!!).
						<br>
						However, you can use the following Kaggle competitions to score your submissions:
						<br>
						<a href="https://www.kaggle.com/competitions/sidd-benchmark-raw-psnr">SIDD Benchmark - RawRGB - PSNR | Kaggle</a>
						<br>
						<a href="https://www.kaggle.com/competitions/sidd-benchmark-srgb-psnr">SIDD Benchmark - sRGB - PSNR | Kaggle</a>
						<br>
						<a href="https://www.kaggle.com/competitions/sidd-benchmark-raw-ssim">SIDD Benchmark - RawRGB - SSIM | Kaggle</a>
						<br>
						<a href="https://www.kaggle.com/competitions/sidd-benchmark-srgb-ssim">SIDD Benchmark - sRGB - SSIM | Kaggle</a>
						<br>
						<a href="https://github.com/AbdoKamel/sidd_kaggle_submit">Example code to prepare your submission for Kaggle</a>
					</p>
                </p>
                <!-- <div class="entry grey-back">
                        <i>
                                <p>
                                        A new version of SIDD Benchmark (<b>SIDD+</b>) is being hosted as a challenge at
                                        the <a target="_blank" href="http://www.vision.ee.ethz.ch/en/ntire20/">New
                                                Trends in Image Restoration
                                                and Enhancement (NTIRE 2020) workshop</a> in conjunction with <a
                                                target="_blank" href="http://cvpr2020.thecvf.com/">CVPR 2020</a>.
                                        <br>
                                        The participating solutions and results will be published in the challenge
                                        report in the CVPR 2020
                                        Workshop proceedings.
                                </p>
                                <p>
                                        Challenges can be accessed at the following Codalab competitions:
                                        <br>
                                        <a target="_blank"
                                                href="https://competitions.codalab.org/competitions/22230">NTIRE 2020
                                                Real Image
                                                Denoising Challenge - Track 1 - rawRGB</a>
                                        <br>
                                        <a target="_blank"
                                                href="https://competitions.codalab.org/competitions/22231">NTIRE 2020
                                                Real Image
                                                Denoising Challenge - Track 2 - sRGB</a>
                                </p>
                        </i>
                </div> -->
                <figure class="cd-image-container">
                        <img src="img/NOISY_SRGB_010_.png" alt="Noisy Image">
                        <span class="cd-image-label" data-type="original">Noisy</span>

                        <div class="cd-resize-img"> <!-- the resizable image on top -->
                                <img src="img/GT_SRGB_010_.png" alt="Ground Truth Image">
                                <span class="cd-image-label" data-type="modified">Ground Truth</span>
                        </div>
                        <span class="cd-handle"></span>
                </figure> <!-- cd-image-container -->
        </div>
        <div class="body-container">
                <p>
                        <b>
                                <a href="#abstract">Abstract</a> |
                                <a href="#papers">Papers</a> |
                                <a href="#code">Code</a> |
                                <a href="#license">License</a> |
                                <a href="#sidd-small">SIDD Small</a> |
                                <a href="#camera-pipeline">Camera Pipeline</a> |
                                <a href="#sidd-medium">SIDD Medium</a> |
                                <a href="#sidd-full">SIDD Full</a> |
                                <a href="#sidd-benchmark">SIDD Benchmark</a> 
                        </b>
                </p>
                <h1 id="abstract">Abstract</h1>
                <p>
                        The last decade has seen an astronomical shift from imaging with DSLR and point-and-shoot
                        cameras to imaging
                        with smartphone cameras. Due to the small aperture and sensor size, smartphone images have
                        notably more
                        noise than their DSLR counterparts. While denoising for smartphone images is an active research
                        area, the
                        research community currently lacks a denoising image dataset representative of real noisy images
                        from
                        smartphone cameras with high-quality ground truth. We address this issue in this paper with the
                        following
                        contributions. We propose a systematic procedure for estimating ground truth for noisy images
                        that can be
                        used to benchmark denoising performance for smartphone cameras. Using this procedure, we have
                        captured a
                        dataset, the Smartphone Image Denoising Dataset (SIDD), of ~30,000 noisy images from 10 scenes
                        under
                        different lighting conditions using five representative smartphone cameras and generated their
                        ground truth
                        images. We used this dataset to benchmark a number of denoising algorithms. We show that
                        CNN-based methods
                        perform better when trained on our high-quality dataset than when trained using alternative
                        strategies, such
                        as low-ISO images used as a proxy for ground truth data.
                </p>

                <h1 id="papers">Papers</h1>
                <p>
                        Abdelrahman Abdelhamed, Lin S., Brown M. S. "A High-Quality Denoising Dataset for Smartphone
                        Cameras", IEEE
                        Computer Vision and Pattern Recognition <b>(CVPR)</b>, June 2018.
                </p>
                <p>
                        [<a href="files/SIDD_CVPR_2018.pdf" target="_blank" rel="noopener"><b>PDF</b></a>] &nbsp;
                        [<a href="#" onclick="javascript:toggleBibtex('SIDDBibtex'); return false;"
                                title="Show/Hide Bibtex"><b>Bibtex</b></a>]
                </p>
                <div id="SIDDBibtex" style="display:none;">
                        <code style="white-space: pre-line;">@InProceedings{SIDD_2018_CVPR,
					author = {Abdelhamed, Abdelrahman and Lin, Stephen and Brown, Michael S.},
					title = {A High-Quality Denoising Dataset for Smartphone Cameras},
					booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
					month = {June},
					year = {2018}
				}</code>
                </div>
                <p>
                        Abdelrahman Abdelhamed, Timofte R., Brown M. S., et al. "NTIRE 2019 Challenge on Real Image
                        Denoising:
                        Methods and Results", IEEE Computer Vision and Pattern Recognition Workshops <b>(CVPRW)</b>,
                        June 2019.
                </p>
                <p>
                        [<a href="http://openaccess.thecvf.com/content_CVPRW_2019/papers/NTIRE/Abdelhamed_NTIRE_2019_Challenge_on_Real_Image_Denoising_Methods_and_Results_CVPRW_2019_paper.pdf"
                                target="_blank" rel="noopener"><b>PDF</b></a>] &nbsp;
                        [<a href="#" onclick="javascript:toggleBibtex('NTIREBibtex'); return false;"
                                title="Show/Hide Bibtex"><b>Bibtex</b></a>]
                </p>
                <div id="NTIREBibtex" style="display:none;">
                        <code style="white-space: pre-line;">@InProceedings{Abdelhamed_2019_CVPR_Workshops,
					author = {Abdelhamed, Abdelrahman and Timofte, Radu and Brown, Michael S. and others},
					title = {NTIRE 2019 Challenge on Real Image Denoising: Methods and Results},
					booktitle = {The IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
					month = {June},
					year = {2019}
				}</code>
                </div>
                <h1 id="code">Code</h1>
                <p>
                        <a href="https://github.com/AbdoKamel/sidd-ground-truth-image-estimation" target="_blank"
                                rel="noopener"><b>Ground-truth image estimation</b></a>
                </p>
                <p>
                        <a href="https://github.com/AbdoKamel/simple-camera-pipeline" target="_blank"
                                rel="noopener"><b>A simple
                                        camera pipeline</b></a> for rendering raw-RGB images into sRGB.
                </p>
                <h1 id="license">License</h1>
                <p>The dataset and the associated code repositories are under the MIT License.</p>
                <h1>Contact</h1>
                <p>
                        For any questions, remarks, or comments, please contact: <a
                                href="mailto:abdoukamel@gmail.com?subject=SIDD">Abdelrahman Abdelhamed</a>.
                </p>
        </div>
        <div class="body-container"> <!-- Dataset -->
                <h1 id="sidd-small">SIDD-Small Dataset</h1>
                <p>
                        <!--[<b><a href="browse.php">Browse</a></b>]-->
                        <!-- <a href="browse.php" class="button">Browse</a> -->
                        <!--
                [<b><a href="ftp://sidd_user:sidd_2018@130.63.97.225/SIDD_Small.zip" target="_blank"  rel="noopener">Download the SIDD Small Dateset (16.18 GB)</a></b>]
                <br>
                [<b><a href="https://ln.sync.com/dl/50b6e5590/jwryqexn-kfkarepd-x4hdqzxs-ad3696zz" target="_blank"  rel="noopener">Download the SIDD Small Dateset (16.18 GB)</a></b>] <br>
                [<b><a href="https://mega.nz/#!tMsE0SpB!7csX9Le8rvHrxCknPHA9_5T2K49TDy1RCdXZc20NMtQ" target="_blank"  rel="noopener">Alternative link</a></b>]  <br>
            -->
                <h2>Download</h2>
                <p>
                        Raw-RGB images only (~10 GB)
                        [
                        <b><a href="http://130.63.97.225/share/SIDD_Small_Raw_Only.zip" target="_blank"
                                        rel="noopener" download>Mirror 1</a></b> |
                        <b><a href="https://competitions.codalab.org/my/datasets/download/aba42bbb-958d-4a13-a49e-54c128be9347"
                                        target="_blank" rel="noopener">Mirror 2</a></b>
                        ]
                        <br>
                        MD5: c033f580fb64aa549679d056d1cf796a &nbsp; SHA1: 932c39f4fc5410dda934a3493ddb46c31b8a5e90
                </p>
                <p>
                        sRGB images only (~6 GB)
                        [
                        <b><a href="http://130.63.97.225/share/SIDD_Small_sRGB_Only.zip" target="_blank"
                                        rel="noopener" download>Mirror 1</a></b> |
                        <b><a href="https://competitions.codalab.org/my/datasets/download/a26784fe-cf33-48c2-b61f-94b299dbc0f2"
                                        target="_blank" rel="noopener">Mirror 2</a></b>
                        ]
                        <br>
                        MD5: 796971867583bf14677dcae510e52538 &nbsp; SHA1: 5a4aa6aa7abcf7b0b56c88ad578fea9a4ff77935
                </p>
                <p>We provide a small version of the dataset that consists of <b>160 image pairs (noisy and
                                ground-truth)</b>
                        representing 160 scene instances. These images can be used for training/learning purposes.
                </p>
                <p>For each image, the following is provided:
                </p>
                <p>
                <ol>
                        <li>Noisy Raw-RGB image (.MAT).</li>
                        <ul>
                                <li>Black Level subtracted, normalized to [0, 1].</li>
                        </ul>
                        <li>Ground truth Raw-RGB image (.MAT).</li>
                        <ul>
                                <li>Black Level subtracted, normalized to [0, 1].</li>
                        </ul>
                        <li>Noisy sRGB image (.PNG).</li>
                        <ul>
                                <li>Gamma corrected, without any tone mapping.</li>
                        </ul>
                        <li>Ground truth sRGB image (.PNG).</li>
                        <ul>
                                <li>Gamma corrected, without any tone mapping.</li>
                        </ul>
                        <li>Metadata extracted from the DNG file (.MAT).</li>
                        <ul>
                                <li>For example, black and saturation levels, as-shot neutral, noise level function,
                                        etc.</li>
                        </ul>
                        <!--<li>Per-pixel noise variance estimated in the Raw-RGB space (.MAT).</li>
                <ul>
                    <li>Measured from stacks of 150 images, assuming per-pixel Gaussian noise in temporal domain (see <a href="files/SIDD_CVPR_2018.pdf" target="_blank">the paper </a> for more details).</li>
                </ul>-->
                </ol>
                </p>
                <h1 id="camera-pipeline">Camera Pipeline (Rendering from raw-RGB to sRGB)</h1>
                <p>
                        We provide a simple and light-weight camera image processing pipeline implemented in MATLAB.
                        This pipeline
                        can be used to render the raw-RGB images into sRGB images with optional tone mapping.
                </p>
                <p>
                        [ <a href="https://github.com/AbdoKamel/simple-camera-pipeline" target="_blank">GitHub<a> | <a
                                                href="https://www.mathworks.com/matlabcentral/fileexchange/70005-simple-camera-pipeline"
                                                target="_blank">MathWorks</a> ]
                </p>
                <h1 id="sidd-medium">SIDD-Medium Dataset</h1>
                The SIDD Medium dataset is similar to SIDD Small dataset excpet that SIDD Medium consists of <b>320
                        image pairs
                        (noisy and ground-truth)</b>, two image pairs from each scene instance.
                <h2>Download</h2>
                <p>Raw-RGB images only (~20 GB)
                        <br>
                        <b><a href="http://130.63.97.225/share/SIDD_Medium_Raw.zip" target="_blank"
                                        rel="noopener" download>Mirror 1</a></b>
                        <br>
                        <b>Mirror 2</b> (parts):
                        [
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/6bf5aadd-ab08-43e2-bbff-f56b631b8d15">Part
                                0</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/f3fd938d-d693-44a2-bcda-e1ba4b9f60bc">Part
                                1</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/919a86de-25c7-4e62-84c8-ccccda67000d">Part
                                2</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/4e201cbc-0b50-428e-9dd6-8fce959883d3">Part
                                3</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/48d11e4b-67d1-4904-9562-265a457214a9">Part
                                4</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/c52e35aa-1e73-423f-a0a7-f95e13b8bbb9">Part
                                5</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/979a70d5-1306-4d32-a33e-7e9c925c5952">Part
                                6</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/9b596aa1-8562-4972-9d70-7826db1106dd">Part
                                7</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/fcb4b939-0ff6-497b-83d3-347d815ac395">Part
                                8</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/9f7e5e57-b324-43fd-8b15-530b90ff99ad">Part
                                9</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/fa9c37ca-d2df-4e64-8afd-1c4d985f600b">Part
                                10</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/697e2f7d-adfa-4bad-9df2-4b18188f70e4">Part
                                11</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/9fd75bba-29ed-4ccf-a305-f003116d8966">Part
                                12</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/96dd024a-8317-4649-b1b1-46989506fb94">Part
                                13</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/5f416d82-8342-4eaa-991a-ac1793141880">Part
                                14</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/65ce66e9-5231-4545-b5e0-4966ae5a476b">Part
                                15</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/79b6e06a-fecc-4320-a313-d329809f0831">Part
                                16</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/29d18514-5464-43a4-bfae-bd5be1adefee">Part
                                17</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/df801a17-c355-49d1-82e6-df1056b762b5">Part
                                18</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/f62d6786-ed79-4e12-b8ba-eb53b0dc17d7">Part
                                19</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/4edc9a00-e009-4fc1-912e-00910dcc32ff">Part
                                20</a>
                        ]
                        <br>
                        To unzip the file parts, run:
                        <br>
                        <code>
                zip -FF SIDD_Medium_Srgb_Parts.zip --out combined.zip
                <br>
                unzip combined.zip
            </code>
                        <br>
                        MD5: 0f44ddb6ec820271c9996aa32a9cc270 &nbsp; SHA1: 886259b1c5e139dbd05a5d02cbca526b12849825
                </p>
                <p>
                        sRGB images only (~12 GB)
                        <br>
                        <b><a href="http://130.63.97.225/share/SIDD_Medium_Srgb.zip" target="_blank"
                                        rel="noopener" download>Mirror 1</a></b>
                        <br>
                        <b>Mirror 2</b> (parts): [
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/f5c7a97d-5431-4cc0-a101-f2d2fd1665f7">Part
                                0</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/7f9926e6-af3d-406c-830a-c5b785548341">Part
                                1</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/3a3ec1c4-005f-41f6-8769-c467a99e4bcf">Part
                                2</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/feb8c3f7-341d-498a-9852-a3459aca4c5c">Part
                                3</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/0b633399-cfa9-45ff-97e5-d585d2638f48">Part
                                4</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/b0b430e3-920e-4778-af5e-4792d7280425">Part
                                5</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/f97a3560-fa74-452b-8bf4-292a97121b6a">Part
                                6</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/3cb70d7e-8361-42d4-a253-58842a39042e">Part
                                7</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/cb89c789-dd2f-45cc-833b-35fb877f7661">Part
                                8</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/a8bd4014-60f0-4e8e-a252-22d02d473fc3">Part
                                9</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/cd80db16-11d9-461a-9241-d93a9c1783d3">Part
                                10</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/da6fb676-7acd-450e-aff3-693b938e233e">Part
                                11</a> |
                        <a
                                href="https://competitions.codalab.org/my/datasets/download/07378dc1-8434-434a-b902-16a78a2ab53f">Part
                                12</a>
                        ]
                        <br>
                        To unzip the file parts, run:
                        <br>
                        <code>
                zip -FF SIDD_Medium_Srgb_Parts.zip --out combined.zip
                <br>
                unzip combined.zip
            </code>
                        <br>
                        MD5: f95b4bc9ec1dd3fe4ebd61aeacad3991 &nbsp; SHA1: b0f895258112db896d6ade0a8ddafc8cfc9bd54d
                </p>
                <h1 id="sidd-full">SIDD-Full Dataset</h1>
                <p>We provide 80% (<b>~24,000 images</b>) of the dataset for training/learning purposes. The rest of the
                        dataset
                        is held for the benchmark. <!--<a href="benchmark.php"><b>the benchmark</b></a>.-->
                </p>
                <p>Below, we provide links to <b>160 scene instances</b>. For each scene instance, the following is
                        provided:
                </p>
                <p>
                <ol>
                        <li>150 noisy Raw-RGB image (.MAT).</li>
                        <ul>
                                <li>Black Level subtracted, normalized to [0, 1].</li>
                        </ul>
                        <li>150 ground truth Raw-RGB image (.MAT).</li>
                        <ul>
                                <li>Black Level subtracted, normalized to [0, 1].</li>
                        </ul>
                        <li>150 noisy sRGB image (.PNG).</li>
                        <ul>
                                <li>Gamma corrected, without any tone mapping.</li>
                        </ul>
                        <li>150 ground truth sRGB image (.PNG).</li>
                        <ul>
                                <li>Gamma corrected, without any tone mapping.</li>
                        </ul>
                        <li>150 metadata extracted from the DNG file (.MAT).</li>
                        <ul>
                                <li>For example, black and saturation levels, as-shot neutral, noise level function,
                                        etc.</li>
                        </ul>
                </ol>
                </p>
                <p>Note: scene instances appearing in gray are held for benchmark.</p>
                <h3>Image directory naming convention</h3>
                <p>Each image is stored in a directory with the name of the scene instance as follows: <br>
                        <b>[scene-instance-number]_[scene_number]_[smartphone-camera-code]_[ISO-level]_[shutter-speed]_[illuminant-temperature]_[illuminant-brightness-code]
                        </b>
                        <br>
                        where "smartphone-camera-code" is one of the following:
                        <br>
                <ul>
                        <li>GP: Google Pixel</li>
                        <li>IP: iPhone 7</li>
                        <li>S6: Samsung Galaxy S6 Edge</li>
                        <li>N6: Motorola Nexus 6</li>
                        <li>G4: LG G4</li>
                </ul>
                and "illuminant-brightness-code" is one of the following:
                <ul>
                        <li>L: low light</li>
                        <li>N: normal brightness</li>
                        <li>H: high exposure</li>
                </ul>
                For example, the following directory name:
                <br>
                0052_002_S6_01600_01000_5500_N
                <br>
                means that this is scene instance 52, from scene 2, captured be Samsung Galaxy S6 Edge (S6), using ISO
                level of
                1600, using shutter speed of 1000 (i.e., exposure time of 1/1000 second), under illuminant temperature
                of 5500K,
                under normal (N) brightness.
                </p>
                <h3>Useful metadata</h3>
                <p>Bayer pattern for each camera: <a href="files/bayer_patterns.csv" target="_blank"
                                rel="noopener"><b>bayer_patterns.csv</b></a></p>
                <p>Camera noise level functions (NLF) as extracted from DNG files: <a
                                href="files/noise_level_functions.csv" target="_blank"
                                rel="noopener"><b>noise_level_functions.csv</b></a></p>
                <h3>DNG images</h3>
                <p><a href="http://130.63.97.225/share/sidd_dng/" target="_blank" rel="noopener" download>DNG images
                                corresponding to
                                noisy raw-RGB images</a></p>
                <p>The first four digits in each DNG archive should match the corresponding scene instance number</p>
                <p>For example: "<b>0001</b>_DNG.zip" corresponds to "<b>0001</b>_001_S6_00100_00060_3200_L"</p>
                <h3>Download</h3>
                <!--<p><em>TODO: Provide a torrent file for easy sharing of the dataset.</em></p>-->
                <p>Text files containing all links to the files below that can be used for batch-downloading (e.g.,
                        using custom
                        scripts or download managers):<br> <a href="files/SIDD_URLs.txt" target="_blank"
                                rel="noopener"><b>Mirror
                                        1</b></a> | <a href="files/SIDD_URLs_Mirror_2.txt" target="_blank"
                                rel="noopener"><b>Mirror
                                        2</b></a></p>
                <p><b><a href="http://130.63.97.225/share/SIDD_Full/index.html" target="_blank" download>Download individual scene instances</a></b></p>

        </div> <!-- Dataset -->
        <!-- Benchmark -->

        <div class="body-container">
                <h1 id="sidd-benchmark">SIDD Benchmark</h1>
                <div>
                        <i>
                                <p>
                                        A new version of SIDD Benchmark (<b>SIDD+</b>) was hosted as a challenge at
                                        the <a target="_blank" href="http://www.vision.ee.ethz.ch/en/ntire20/">New
                                                Trends in Image Restoration and Enhancement (NTIRE 2020) workshop</a> in
                                        conjunction with <a target="_blank" href="http://cvpr2020.thecvf.com/">CVPR
                                                2020</a>.
                                        <br>
                                        The participating solutions and results will be published in the challenge
                                        report in the CVPR 2020 Workshop proceedings.
                                </p>
                                <p>
                                        Challenges can be accessed at the following Codalab competitions:
                                        <br>
                                        <a target="_blank"
                                                href="https://competitions.codalab.org/competitions/22230">NTIRE 2020
                                                Real Image Denoising Challenge - Track 1 - rawRGB</a>
                                        <br>
                                        <a target="_blank"
                                                href="https://competitions.codalab.org/competitions/22231">NTIRE 2020
                                                Real Image Denoising Challenge - Track 2 - sRGB</a>
                                </p>
                                <!--
                                <p>
                                        The benchmark is currently hosted here on this website.
                                </p>
                                -->
                        </i>
                </div>
                <h2>Download</h2>
                <p>
                        <b><a href="http://130.63.97.225/share/download_benchmark.html" target="_blank">Go to download page</a></b>
                </p>
                
                <h2>Description</h2>
                <p>The SIDD Benchmark consists of <b>40 images</b> representing 40 scene instances. These images can be
                        used to benchmark denoising methods.</p>
                <p>For each image, the following is provided in one directory:</p>
                <p>
                <ol>
                        <li>Noisy Raw-RGB image (.MAT). Black Level subtracted, normalized to [0, 1].</li>
                        <li>Noisy sRGB image (.PNG). Gamma corrected, without any tone mapping.</li>
                        <li>Metadata extracted from the DNG file (.MAT). For example, black and saturation levels,
                                as-shot neutral, noise level function, etc.</li>
                </ol>
                </p>
                <p>
                        The PSNR and SSIM values are calculated only on 32 blocks of size 256 by 256 pixels.
                        The block positions are provided in a file named "BenchmarkBlocks32.mat".
                </p>
                <p>Follow the instructions in the <b>Code_v/_ReadMe.txt</b> file to
                <ul>
                        <li>demonstrate the code, </li>
                        <li>run your own denoising method on the benchmark, and/or </li>
                        <li><b>submit</b> your results for evaluation.</li>
                </ul>
                </p>
                <h2>Upload your results</h2>
                <a href="http://130.63.97.225/sidd/benchmark_submit.php" class="button">Click here to submit your
                        results</a>
                <h2>Benchmark Results</h2>
                <p>
                        Results of the NTIRE 2019 Challenge on Real Image Denoising can be found in
                        <a href="http://openaccess.thecvf.com/content_CVPRW_2019/papers/NTIRE/Abdelhamed_NTIRE_2019_Challenge_on_Real_Image_Denoising_Methods_and_Results_CVPRW_2019_paper.pdf"
                                target="_blank" rel="noopener"><b>this paper</b></a>.
                </p>
                <p>
                        The following tables show the benchmark results published in <a href="files/SIDD_CVPR_2018.pdf"
                                target="_blank"><b>the paper</b></a>.
                </p>
                <h2>Results of denoising in raw-RGB space</h2>
                <a href="http://130.63.97.225/sidd/bench_res_raw.html" target="_blank">Raw-RGB results</a>
                <h2>Results of denoising in sRGB space</h2>
                <a href="http://130.63.97.225/sidd/bench_res_sRGB.html" target="_blank">sRGB results</a>
        </div>
        <div class="footer">
        </div>
</body>

</html>